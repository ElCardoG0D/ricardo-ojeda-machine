# ============================================================
#  DAG: ricardo_ml_dag.py
# Orquesta los pipelines de Kedro (regresi贸n + clasificaci贸n)
# ============================================================

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.bash import BashOperator

# ============================================================
# 1锔 Configuraci贸n general del DAG
# ============================================================
default_args = {
    "owner": "Ricardo Ojeda",
    "depends_on_past": False,
    "email": ["ml_project@airflow.local"],
    "email_on_failure": False,
    "email_on_retry": False,
    "retries": 1,
    "retry_delay": timedelta(minutes=2),
}

dag = DAG(
    dag_id="ricardo_ml_dag",
    default_args=default_args,
    description="Orquestaci贸n de pipelines Kedro para Regresi贸n y Clasificaci贸n",
    schedule_interval=None,  # Ejecuci贸n manual
    start_date=datetime(2025, 10, 27),
    catchup=False,
    tags=["kedro", "machine_learning", "ricardo_ojeda_machine"],
)

# ============================================================
# 2锔 Tareas del pipeline
# ============================================================

# --- 1锔 Ejecuci贸n del pipeline de preparaci贸n de datos ---
prepare_task = BashOperator(
    task_id="data_preparation",
    bash_command="cd /opt/airflow/project && kedro run --pipeline=data_preparation",
    dag=dag,
)

# --- 2锔 Ejecuci贸n del pipeline de regresi贸n ---
regression_task = BashOperator(
    task_id="regression_pipeline",
    bash_command="cd /opt/airflow/project && kedro run --pipeline=regression",
    dag=dag,
)

# --- 3锔 Ejecuci贸n del pipeline de clasificaci贸n ---
classification_task = BashOperator(
    task_id="classification_pipeline",
    bash_command="cd /opt/airflow/project && kedro run --pipeline=classification",
    dag=dag,
)

# ============================================================
#  DVC Push (desactivado para entrega)
# ============================================================
# Si deseas activarlo m谩s adelante, quita los comentarios
# y aseg煤rate de tener un remote configurado en DVC.
# dvc_push_task = BashOperator(
#     task_id="dvc_push",
#     bash_command="cd /opt/airflow/project && dvc push",
#     dag=dag,
# )

# ============================================================
# 3锔 Dependencias del flujo
# ============================================================
# prepare_task >> [regression_task, classification_task] >> dvc_push_task
prepare_task >> [regression_task, classification_task]
